{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwkFPvF+IwiHTMiwjUFPs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gladiator07/Deep-Learning-with-PyTorch/blob/main/Linear_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN4FzEtvCAv2"
      },
      "source": [
        "PyTorch has a whole submodule dedicated to neural networks, called torch.nn. It contains the building blocks needed to create all sorts of neural network architectures. Those building blocks are called modules in PyTorch parlance (such building blocks are often referred to as layers in other frameworks). A PyTorch module is a Python class deriving from the nn.Module base class. A module can have one or more Parameter instances as attributes, which are tensors whose values are optimized during the training process (think w and b in our linear model). A module can also have one or more submodules (subclasses of nn.Module) as attributes, and it will be able to track their parameters as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSXEztkZCFX0"
      },
      "source": [
        "NOTE: The submodules must be top-level attributes, not buried inside list or dict instances! Otherwise, the optimizer will not be able to locate the submodules (and, hence, their parameters). For situations where your model requires a list or dict of submodules, PyTorch provides nn.ModuleList and nn.ModuleDict. \r\n",
        "\r\n",
        "\r\n",
        "Unsurprisingly, we can find a subclass of nn.Module called nn.Linear, which applies an affine transformation to its input (via the parameter attributes weight and bias) and is equivalent to what we implemented earlier in our thermometer experiments. We’ll now start precisely where we left off and convert our previous code to a form that uses nn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI9jYrmqEb6K"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubXWXS8BEeql",
        "outputId": "dd01e3e0-a28e-4c74-b958-2493cbbc56cd"
      },
      "source": [
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\r\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\r\n",
        "t_c = torch.tensor(t_c).unsqueeze(1) # <1>\r\n",
        "t_u = torch.tensor(t_u).unsqueeze(1) # <1>\r\n",
        "\r\n",
        "t_u.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkwnBXNSEgzo",
        "outputId": "0683e872-76f7-46ae-bdbe-ae9186e4c364"
      },
      "source": [
        "n_samples = t_u.shape[0]\r\n",
        "n_val = int(0.2 * n_samples)\r\n",
        "\r\n",
        "shuffled_indices = torch.randperm(n_samples)\r\n",
        "\r\n",
        "train_indices = shuffled_indices[:-n_val]\r\n",
        "val_indices = shuffled_indices[-n_val:]\r\n",
        "\r\n",
        "train_indices, val_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3, 10,  9,  7,  8,  6,  5,  0,  1]), tensor([4, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-tLxabEixu"
      },
      "source": [
        "t_u_train = t_u[train_indices]\r\n",
        "t_c_train = t_c[train_indices]\r\n",
        "\r\n",
        "t_u_val = t_u[val_indices]\r\n",
        "t_c_val = t_c[val_indices]\r\n",
        "\r\n",
        "t_un_train = 0.1 * t_u_train\r\n",
        "t_un_val = 0.1 * t_u_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U4ToUGOGMPS"
      },
      "source": [
        "The constructor to nn.Linear accepts three arguments: the number of input features, the number of output features, and whether the linear model includes a bias or not (defaulting to True, here):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NNdGbbC1NN",
        "outputId": "1cc9520b-fb7c-4fc0-f678-a697543c6043"
      },
      "source": [
        "linear_model = nn.Linear(1, 1)\r\n",
        "linear_model(t_un_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3387],\n",
              "        [0.3465]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EflQT0DIGe0Z"
      },
      "source": [
        "The number of features in our case just refers to the size of the input and the output tensor for the module, so 1 and 1. If we used both temperature and barometric pressure as input, for instance, we would have two features in input and one feature in output. As we will see, for more complex models with several intermediate modules, the number of features will be associated with the capacity of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462zLLsEF2rw",
        "outputId": "cf3d85c8-0eab-4b11-cec6-771a71e553ed"
      },
      "source": [
        "linear_model.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.0411]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEC0LqU8GyFS",
        "outputId": "82ee61a5-9244-43f8-e864-c1e92d80f02f"
      },
      "source": [
        "linear_model.bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.1076], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxjreCk6G0MW",
        "outputId": "83060ae7-a6ad-4cda-ed8d-44a889f35ef6"
      },
      "source": [
        "x = torch.ones(1)\r\n",
        "linear_model(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1486], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg_P-ZI1HFKh"
      },
      "source": [
        "Although PyTorch lets us get away with it, we don’t actually provide an input with the right dimensionality. We have a model that takes one input and produces one output, but PyTorch nn.Module and its subclasses are designed to do so on multiple samples at the same time. To accommodate multiple samples, modules expect the zeroth dimension of the input to be the number of samples in the batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amaa-ravHGfG"
      },
      "source": [
        "## Batching Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6uh1yyZHBHt",
        "outputId": "3b3399ba-0ab7-4ba1-af15-8f3f1e047311"
      },
      "source": [
        "x = torch.ones(10, 1)\r\n",
        "linear_model(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486],\n",
              "        [0.1486]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS8qBxeLHUrs",
        "outputId": "bd128465-6623-4aa9-8471-a097f9c3ff0d"
      },
      "source": [
        "t_u.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT4_vzcVIL7L"
      },
      "source": [
        "linear_model = nn.Linear(1, 1)\r\n",
        "optimizer = optim.SGD(\r\n",
        "    linear_model.parameters(),\r\n",
        "    lr=1e-2\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54dbG5GqIYhT",
        "outputId": "eb878a1f-6bcb-4e81-c600-51d754068cf1"
      },
      "source": [
        "linear_model.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f84d1c561a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HwSlcnHIaHa",
        "outputId": "5f0529f5-5b9c-4ab0-d337-89a6612aadf7"
      },
      "source": [
        "list(linear_model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.9165]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.6471], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gn1BqKIeiT"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\r\n",
        "                  t_c_train, t_c_val):\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "        t_p_train = model(t_u_train) # <1>\r\n",
        "        loss_train = loss_fn(t_p_train, t_c_train)\r\n",
        "\r\n",
        "        t_p_val = model(t_u_val) # <1>\r\n",
        "        loss_val = loss_fn(t_p_val, t_c_val)\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss_train.backward() # <2>\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if epoch == 1 or epoch % 1000 == 0:\r\n",
        "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\r\n",
        "                  f\" Validation loss {loss_val.item():.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DZ15B1UItf7",
        "outputId": "184b6a3c-b0db-40b0-c1c1-a60edf19d7ce"
      },
      "source": [
        "linear_model = nn.Linear(1, 1)\r\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\r\n",
        "\r\n",
        "training_loop(\r\n",
        "    n_epochs = 3000, \r\n",
        "    optimizer = optimizer,\r\n",
        "    model = linear_model,\r\n",
        "    loss_fn = nn.MSELoss(), # <1>\r\n",
        "    t_u_train = t_un_train,\r\n",
        "    t_u_val = t_un_val, \r\n",
        "    t_c_train = t_c_train,\r\n",
        "    t_c_val = t_c_val)\r\n",
        "\r\n",
        "print()\r\n",
        "print(linear_model.weight)\r\n",
        "print(linear_model.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 272.6239, Validation loss 268.3783\n",
            "Epoch 1000, Training loss 3.5114, Validation loss 2.5710\n",
            "Epoch 2000, Training loss 3.0428, Validation loss 2.5042\n",
            "Epoch 3000, Training loss 3.0355, Validation loss 2.4961\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[5.3721]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-17.2292], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbgwGG_qI7H6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}